{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarand0/Mass-Personalization-in-Recommender-Systems-Independent-Research/blob/main/Mass_Personalization_in_Recommender_Systems_An_Analysis_of_Amazon_User_Ratings_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gSfoESBPxrX"
      },
      "source": [
        "**Mass Personalization in Recommender Systems: An Analysis of Amazon User Ratings Data by Saran Duncan in Collaboration with Research Advisor Professor Forrest Davis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEF-3IeYO3AA"
      },
      "source": [
        "Exploring the use of the Amazon Data from [this](https://amazon-reviews-2023.github.io/index.html#data-fields) repo.\n",
        "\n",
        "### Dataset\n",
        "They provide several processed datasets from May 2000 to Sep. 2023:  I focus on the Amazon data under the category Beauty and Personal Care.\n",
        "\n",
        "train.rating:\n",
        "- Train file.\n",
        "- Each Line is a training instance: userID\\t itemID\\t rating\\t timestamp (if have)\n",
        "\n",
        "test.rating:\n",
        "- Test file (positive instances).\n",
        "- Each Line is a testing instance: userID\\t itemID\\t rating\\t timestamp (if have)\n",
        "\n",
        "test.negative\n",
        "- Test file (negative instances).\n",
        "- Each line corresponds to the line of test.rating, containing 99 negative samples.  \n",
        "- Each line is in the format: (userID,itemID)\\t negativeItemID1\\t negativeItemID2 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWpvDWjhRnEJ"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fkH0KVkXZN8"
      },
      "outputs": [],
      "source": [
        "data = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "                      \"0core_timestamp_Beauty_and_Personal_Care\",\n",
        "                      trust_remote_code=True, split='train').to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pqLFFMpZ2o6"
      },
      "outputs": [],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJYTT9zLX2R1"
      },
      "outputs": [],
      "source": [
        "# Check the length of the DataFrame\n",
        "print(f\"Data Length: {len(data)}\")\n",
        "\n",
        "# Check for max/min values in specific columns\n",
        "print(f\"Max User ID: {data['user_id'].max()}\")\n",
        "print(f\"Min Parent ASIN: {data['parent_asin'].min()}\")\n",
        "print(f\"Min Rating: {data['rating'].min()}\")\n",
        "print(f\"Min Timestamp: {data['timestamp'].min()}\")\n",
        "print(f\"Max Timestamp: {data['timestamp'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul7T2pfjYBC5"
      },
      "outputs": [],
      "source": [
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_MYWVooYZ1K"
      },
      "outputs": [],
      "source": [
        "# Extract a subset of columns and rename them:\n",
        "column_names2 = ['User ID', 'Product ID', 'Rating', 'Timestamp']\n",
        "data_subset = data[['user_id', 'parent_asin', 'rating', 'timestamp']]\n",
        "\n",
        "# Rename columns as 'column_names2' for the subset\n",
        "data_subset.columns = column_names2[0:]\n",
        "\n",
        "# Display the new DataFrame with renamed columns\n",
        "print(data_subset.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ODrg6o_cXgT"
      },
      "outputs": [],
      "source": [
        "#print data with timestamps\n",
        "import pandas as pd\n",
        "timestamps = data['timestamp']\n",
        "df = pd.DataFrame(timestamps)\n",
        "# Convert timestamps to datetime, assuming they are in milliseconds\n",
        "df['date'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "data['year'] = df['date'].dt.year\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWfzivIAtGxc"
      },
      "outputs": [],
      "source": [
        "#number of years a user has rated products for\n",
        "import pandas as pd\n",
        "data.groupby('user_id')['year'].nunique().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3EAomXtt1bh"
      },
      "outputs": [],
      "source": [
        "#Users who gave more than 4 ratings in each year\n",
        "filtered_data = data.groupby(['user_id', 'year'])['rating'].count().reset_index(name='rating_count')\n",
        "filtered_data = filtered_data[filtered_data['rating_count'] > 4]\n",
        "filtered_data = filtered_data.sort_values(by='rating_count', ascending=False)\n",
        "print(filtered_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMNhRQChIF7D"
      },
      "outputs": [],
      "source": [
        "# Get groups of users who rated the same products in the same year\n",
        "product_groups = data.groupby(['parent_asin', 'year'])['user_id'].apply(list).reset_index(name='users')\n",
        "product_groups = product_groups[product_groups['users'].apply(len)>1]\n",
        "product_groups['user count'] = product_groups['users'].apply(len)\n",
        "print(product_groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spNwtcRmvv0R"
      },
      "outputs": [],
      "source": [
        "product_groups.sort_values(by='user count', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFQiUn1Bg03t"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import json\n",
        "\n",
        "def get_avg(product_groups, outfile):\n",
        "\n",
        "    for year in product_groups['year'].unique():\n",
        "        subset = product_groups[product_groups['year'] == year]\n",
        "        subset.to_pickle(f\"./Group{year}.pkl\")\n",
        "\n",
        "        #hashmap to store user overlaps\n",
        "        user_overlap = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        # Iterate through each product group i\n",
        "        for _, row in subset.iterrows():\n",
        "            users = row['users']\n",
        "            num_users = len(users)\n",
        "\n",
        "            # Iterate through all pairs of users within the group\n",
        "            for i in range(num_users):\n",
        "                for j in range(i + 1, num_users):\n",
        "                    user1 = users[i]\n",
        "                    user2 = users[j]\n",
        "\n",
        "                    # Increment the overlap count for both user pairs\n",
        "                    user_overlap[user1][user2] += 1\n",
        "                    user_overlap[user2][user1] += 1\n",
        "\n",
        "        with open(f'user_overlap_{year}.json', 'w') as f:\n",
        "            json.dump(user_overlap, f)\n",
        "\n",
        "        pair_count = 0\n",
        "        avg_overlap = 0\n",
        "        tot_count = 0\n",
        "        for user1, overlaps in user_overlap.items():\n",
        "            for user2, count in overlaps.items():\n",
        "                if count > 1:\n",
        "                    pair_count+=1\n",
        "                    tot_count+=count\n",
        "        if pair_count == 0:\n",
        "            avg_overlap = 0\n",
        "        else:\n",
        "            avg_overlap = tot_count/pair_count\n",
        "        outfile.write(f\"{year}\\t{pair_count}\\t{avg_overlap}\\n\")\n",
        "\n",
        "def main():\n",
        "    # Load data, removing streaming=True to get a regular Dataset\n",
        "    data = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "                          \"0core_timestamp_Beauty_and_Personal_Care\",\n",
        "                          trust_remote_code=True, split='train').to_pandas()\n",
        "    # Convert timestamps to datetime, assuming they are in milliseconds\n",
        "    data['date'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
        "    data['year'] = data['date'].dt.year\n",
        "\n",
        "    # Get product groups\n",
        "    product_groups = data.groupby(['parent_asin', 'year'])['user_id'].apply(list).reset_index(name='users')\n",
        "    product_groups = product_groups[product_groups['users'].apply(len)>1]\n",
        "    product_groups['user count'] = product_groups['users'].apply(len)\n",
        "\n",
        "    outfile = open('info.tsv', 'w')\n",
        "    outfile.write(\"year\\tcount\\tavg\\n\")\n",
        "    get_avg(product_groups, outfile)\n",
        "    outfile.close()\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diliXPCCzgFu"
      },
      "outputs": [],
      "source": [
        "group_2019 = product_groups[product_groups['year']==2019]\n",
        "print(group_2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B-YVZEy2AlS"
      },
      "outputs": [],
      "source": [
        "group_2019.to_pickle(\"./Group2019.pkl\")\n",
        "pd.read_pickle(\"./Group2019.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUlMKdlw8j0a"
      },
      "outputs": [],
      "source": [
        "#Finding similarities for users in 2017\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "group_2019 = pd.read_pickle(\"./Group2019.pkl\")\n",
        "\n",
        "#hashmap to store user overlaps\n",
        "user_overlap = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "# Iterate through each product group in 2017\n",
        "for _, row in group_2019.iterrows():\n",
        "    users = row['users']\n",
        "    num_users = len(users)\n",
        "\n",
        "    # Iterate through all pairs of users within the group\n",
        "    for i in range(num_users):\n",
        "        for j in range(i + 1, num_users):\n",
        "            user1 = users[i]\n",
        "            user2 = users[j]\n",
        "\n",
        "            # Increment the overlap count for both user pairs\n",
        "            user_overlap[user1][user2] += 1\n",
        "            user_overlap[user2][user1] += 1\n",
        "\n",
        "# To print the entire overlap data structure\n",
        "for user1, overlaps in user_overlap.items():\n",
        "    for user2, count in overlaps.items():\n",
        "        if count > 1:\n",
        "          print(f\"User {user1} and User {user2} have {count} product groups in common.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJG2-w1JGPS3"
      },
      "outputs": [],
      "source": [
        "pair_count = 0\n",
        "avg_overlap = 0\n",
        "tot_count = 0\n",
        "for user1, overlaps in user_overlap.items():\n",
        "    for user2, count in overlaps.items(): #count of how many similar product groups exist\n",
        "      if count > 1:\n",
        "        pair_count+=1\n",
        "        tot_count+=count\n",
        "avg_overlap = tot_count/pair_count\n",
        "print(avg_overlap)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWkfCrsjvjs-"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# transform matrix to scipy sparse matrix\n",
        "user_to_product_sparse_df = csr_matrix(user_to_product_df.values)\n",
        "user_to_product_sparse_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INYeTmdrvZ9r"
      },
      "source": [
        "**Fitting K-Nearest Neighbours model to the scipy sparse matrix:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfBGGPshv7td"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "knn_model.fit(user_to_product_sparse_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uqJDB1-wsOB"
      },
      "source": [
        "**Specify User ID and number of similar users we want to consider here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcyh9HoMys99"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pprint import pprint\n",
        "\n",
        "user_id = 'AE2CVCNCDLMNEBC6XZLMTHJTYEXA'\n",
        "print(\" Few of the products rated by the User:\")\n",
        "pprint(list(items_data[items_data['User ID'] == user_id]['Product ID'])[:10])\n",
        "\n",
        "# function to find top n similar users of the given input user\n",
        "def get_similar_users(user, n = 5):\n",
        "  # input to this function is the user and number of top similar users we want\n",
        "  user_index = user_to_product_df.index.get_loc(user) # Get the index corresponding to the user ID\n",
        "  knn_input = np.asarray([user_to_product_df.values[user_index]])\n",
        "  print(knn_input.sum(axis=-1))\n",
        "  distances, indices = knn_model.kneighbors(knn_input, n_neighbors=n+1)\n",
        "\n",
        "  print(\"Top\",n,\"users who are very similar to the user-\",user, \"are: \")\n",
        "  print(\" \")\n",
        "\n",
        "  # Get the user IDs of similar users\n",
        "  similar_users = [user_to_product_df.index[i] for i in indices.flatten()[1:]]\n",
        "\n",
        "  for i, similar_user_id in enumerate(similar_users):\n",
        "    print(i+1,\". User:\", similar_user_id, \"separated by distance of\", distances[0][i+1])\n",
        "\n",
        "  return similar_users, distances.flatten()[1:]  # Return the similar user IDs\n",
        "\n",
        "similar_user_list, distance_list = get_similar_users(user_id,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk3SmOM11opW"
      },
      "source": [
        "**Now we have to pick the top products to recommend. Which we can do by defining weights to ratings made by similar users.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqI39hII157w"
      },
      "outputs": [],
      "source": [
        "similar_user_list, distance_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7OpU5gQ2BJ-"
      },
      "outputs": [],
      "source": [
        "weight_list = distance_list/np.sum(distance_list)\n",
        "weight_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nLnviOE2Gqr"
      },
      "source": [
        "**Getting ratings of all products by derived similar users**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYC4_egK2f8c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "similar_user_indices = [user_to_product_df.index.get_loc(user_id) for user_id in similar_user_list] #Get the indices of similar users.\n",
        "product_ratings_sim_users = (user_to_product_df.values[similar_user_indices]) * weight_list[:, np.newaxis] #Use the indices to select rows.\n",
        "product_ratings_sim_users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms-rcWen3BbL"
      },
      "outputs": [],
      "source": [
        "products_list = user_to_product_df.columns\n",
        "products_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG6C2xz04aFe"
      },
      "outputs": [],
      "source": [
        "print(\"Weight list shape:\", len(weight_list))\n",
        "print(\"product_ratings_sim_users shape:\", product_ratings_sim_users.shape)\n",
        "print(\"Number of products:\", len(products_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWQd0fho44-b"
      },
      "source": [
        "**Broadcasting weightage matrix to similar user rating matrix, so that it is compatible for matrix operations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyzCxRAf5BkB"
      },
      "outputs": [],
      "source": [
        "weight_list = weight_list[:,np.newaxis] + np.zeros(len(products_list))\n",
        "weight_list.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXnIPNYv5LKS"
      },
      "outputs": [],
      "source": [
        "new_rating_matrix = weight_list*product_ratings_sim_users\n",
        "mean_rating_list = new_rating_matrix.sum(axis =0)\n",
        "mean_rating_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ezzOi3B5tuX"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "def recommend_products(n):\n",
        "  n = min(len(mean_rating_list),n)\n",
        "  pprint(list(products_list[np.argsort(mean_rating_list)[::-1][:n]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj7-d2qb551C"
      },
      "outputs": [],
      "source": [
        "print(\"Products recommended based on similar users are: \")\n",
        "recommend_products(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3iQ0B0Kj52e"
      },
      "outputs": [],
      "source": [
        "#Plotting a Scatterplot of the avg number of product groups in common over the range of years\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('info.tsv', sep='\\t')\n",
        "    fig = px.scatter(df,\n",
        "                     x='year',\n",
        "                     y='avg',\n",
        "                     #size='count',\n",
        "                     hover_name='year',\n",
        "                     title='Average Number of Product Groups in Common Over the Years',\n",
        "                     labels={'year': 'Year', 'avg': 'Average Overlap', 'count': 'Number of Pairs'})\n",
        "\n",
        "    fig.show()\n",
        "except pd.errors.EmptyDataError:\n",
        "    print(\"The file 'info.tsv' is empty or has an incorrect format. Please check the data and file format.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"The file 'info.tsv' was not found. Please ensure it has been created and is in the correct directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi8fajrln7jh"
      },
      "outputs": [],
      "source": [
        "#Plotting a Scatterplot of the avg number of product groups in common over the range of years, with each point size reflecting the number of user pairings\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('info.tsv', sep='\\t')\n",
        "    fig = px.scatter(df,\n",
        "                     x='year',\n",
        "                     y='avg',\n",
        "                     hover_name='year',\n",
        "                     title='Average Number of Product Groups in Common Over the Years',\n",
        "                     labels={'year': 'Year', 'avg': 'Average Overlap'})\n",
        "\n",
        "    fig.show()\n",
        "except pd.errors.EmptyDataError:\n",
        "    print(\"The file 'info.tsv' is empty or has an incorrect format. Please check the data and file format.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"The file 'info.tsv' was not found. Please ensure it has been created and is in the correct directory.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}